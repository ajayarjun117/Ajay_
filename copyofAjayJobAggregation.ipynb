{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpxMSrtjB2HZlk2j9Y3teS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayarjun117/Ajay_/blob/main/copyofAjayJobAggregation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {BASE_DIR}/tools.py\n",
        "from typing import Dict, Any, List, Optional\n",
        "from dataclasses import dataclass\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from playwright.sync_api import sync_playwright\n",
        "import re\n",
        "\n",
        "@dataclass\n",
        "class PageResult:\n",
        "    final_url: str\n",
        "    html: str\n",
        "\n",
        "def fetch_rendered_html_impl(url: str, wait_selector: Optional[str] = None, timeout_ms: int = 15000) -> PageResult:\n",
        "    with sync_playwright() as p:\n",
        "        browser = p.chromium.launch(headless=True)\n",
        "        page = browser.new_page()\n",
        "        page.set_extra_http_headers({\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36\",\n",
        "            \"Accept-Language\": \"en-US,en;q=0.9\"\n",
        "        })\n",
        "        page.goto(url, wait_until=\"networkidle\")\n",
        "        # gentle scroll to trigger lazy load\n",
        "        for _ in range(6):\n",
        "            page.keyboard.press(\"End\")\n",
        "            page.wait_for_timeout(900)\n",
        "        if wait_selector:\n",
        "            try:\n",
        "                page.wait_for_selector(wait_selector, timeout=timeout_ms)\n",
        "            except Exception:\n",
        "                pass\n",
        "        html = page.content()\n",
        "        final_url = page.url\n",
        "        browser.close()\n",
        "    return PageResult(final_url=final_url, html=html)\n",
        "\n",
        "def _text(el):\n",
        "    return re.sub(r\"\\s+\", \" \", el.get_text(strip=True)) if el else None\n",
        "\n",
        "def parse_generic_listings_impl(base_url: str, html: str, company: Optional[str] = None) -> List[Dict[str, Any]]:\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    items = []\n",
        "    for a in soup.find_all(\"a\", href=True):\n",
        "        href = a[\"href\"]\n",
        "        text = _text(a)\n",
        "        if not text or len(text) < 4:\n",
        "            continue\n",
        "        if re.search(r\"(careers|jobs|positions|opening|opportunit|apply)\", href, re.I):\n",
        "            card = a.find_parent([\"li\", \"article\", \"div\"]) or a\n",
        "            # location\n",
        "            loc = None\n",
        "            for sel in [\".location\", \"[data-location]\"]:\n",
        "                try:\n",
        "                    cand = card.select_one(sel)\n",
        "                    if cand:\n",
        "                        loc = _text(cand); break\n",
        "                except Exception:\n",
        "                    pass\n",
        "            # description\n",
        "            desc_el = None\n",
        "            for dsel in [\".description\", \".job-snippet\", \"p\", \"summary\", \"li\"]:\n",
        "                try:\n",
        "                    cand = card.select_one(dsel)\n",
        "                    if cand and _text(cand) and _text(cand) != text:\n",
        "                        desc_el = cand; break\n",
        "                except Exception:\n",
        "                    pass\n",
        "            items.append({\n",
        "                \"job_title\": text,\n",
        "                \"location\": loc,\n",
        "                \"company\": company,\n",
        "                \"description_snippet\": _text(desc_el) if desc_el else None,\n",
        "                \"apply_link\": urljoin(base_url, href),\n",
        "            })\n",
        "    # de-dup\n",
        "    out, seen = [], set()\n",
        "    for r in items:\n",
        "        key = (r[\"job_title\"], r[\"apply_link\"])\n",
        "        if key not in seen:\n",
        "            seen.add(key); out.append(r)\n",
        "    return out[:100]\n",
        "\n",
        "def parse_google_careers_impl(html: str) -> List[Dict[str, Any]]:\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    records = []\n",
        "    for li in soup.select('[role=\"listitem\"], li, article'):\n",
        "        a = li.select_one(\"a[aria-label], a[jsname], a[href]\") or li.find(\"a\")\n",
        "        if not a:\n",
        "            continue\n",
        "        title = _text(a)\n",
        "        href = a.get(\"href\")\n",
        "        if not title or not href:\n",
        "            continue\n",
        "        loc_el = li.select_one(\"[data-location], .Gc7T-, .location\") or li.find(string=re.compile(\"Location\", re.I))\n",
        "        loc = _text(loc_el.parent) if hasattr(loc_el, \"parent\") else _text(loc_el)\n",
        "        desc_el = li.select_one(\".Zqg4Je, .job-snippet, p\")\n",
        "        records.append({\n",
        "            \"job_title\": title,\n",
        "            \"location\": loc,\n",
        "            \"company\": \"Google\",\n",
        "            \"description_snippet\": _text(desc_el),\n",
        "            \"apply_link\": href if href.startswith(\"http\") else f\"https://careers.google.com{href}\",\n",
        "        })\n",
        "    return records\n",
        "\n",
        "def parse_meta_careers_impl(base_url: str, html: str) -> List[Dict[str, Any]]:\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    out = []\n",
        "    for card in soup.select(\"article, .job-card, ._8_1x, li\"):\n",
        "        a = card.find(\"a\", href=True)\n",
        "        if not a:\n",
        "            continue\n",
        "        title = _text(a)\n",
        "        href = urljoin(base_url, a[\"href\"])\n",
        "        if not title or not href:\n",
        "            continue\n",
        "        loc = None\n",
        "        for sel in [\"[data-testid='location']\", \".jobs-location\", \"._8_1y\", \"[aria-label*='Location']\"]:\n",
        "            el = card.select_one(sel)\n",
        "            if el:\n",
        "                loc = _text(el); break\n",
        "        desc_el = card.select_one(\".job-snippet, p, .description\")\n",
        "        out.append({\n",
        "            \"job_title\": title,\n",
        "            \"location\": loc,\n",
        "            \"company\": \"Meta\",\n",
        "            \"description_snippet\": _text(desc_el),\n",
        "            \"apply_link\": href,\n",
        "        })\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhHolD-ZMcsG",
        "outputId": "56e3276d-3d75-43b8-8f33-12f29323c62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/job_crew/tools.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {BASE_DIR}/main.py\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from crewai import Agent  # still using CrewAI agents for the POC narrative\n",
        "from tools import (\n",
        "    fetch_rendered_html_impl,\n",
        "    parse_generic_listings_impl,\n",
        "    parse_google_careers_impl,\n",
        "    parse_meta_careers_impl,\n",
        ")\n",
        "\n",
        "# Agents without tools (to avoid version issues). We'll call functions directly.\n",
        "navigator = Agent(\n",
        "    role=\"Web Navigator\",\n",
        "    goal=\"Render a given careers URL (JS included) and return final_url + html.\",\n",
        "    backstory=\"Handles dynamic, JS-heavy pages and waits for relevant content to load.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "extractor = Agent(\n",
        "    role=\"DOM Extractor\",\n",
        "    goal=\"Extract jobs: title, location, company, description snippet, apply link.\",\n",
        "    backstory=\"Understands common careers page patterns; falls back to heuristics.\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "def render_page(url: str) -> Dict[str, str]:\n",
        "    res = fetch_rendered_html_impl(url)\n",
        "    return {\"final_url\": res.final_url, \"html\": res.html}\n",
        "\n",
        "def extract_records(final_url: str, html: str, company_hint: Optional[str]) -> List[Dict[str, Any]]:\n",
        "    if \"careers.google.com\" in final_url:\n",
        "        recs = parse_google_careers_impl(html)\n",
        "    elif \"metacareers.com\" in final_url or \"facebook.com/careers\" in final_url:\n",
        "        recs = parse_meta_careers_impl(final_url, html)\n",
        "    else:\n",
        "        recs = parse_generic_listings_impl(final_url, html, company=company_hint)\n",
        "    for r in recs:\n",
        "        if company_hint and not r.get(\"company\"):\n",
        "            r[\"company\"] = company_hint\n",
        "    return recs\n",
        "\n",
        "def run_on_url(url: str, company_hint: Optional[str] = None) -> List[Dict[str, Any]]:\n",
        "    nav = render_page(url)\n",
        "    return extract_records(nav[\"final_url\"], nav[\"html\"], company_hint)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_urls = [\n",
        "        \"https://careers.google.com/jobs/results/\",   # Google\n",
        "        \"https://www.metacareers.com/jobs/\",          # Meta\n",
        "        \"https://stripe.com/jobs/search\",             # Third site (example)\n",
        "    ]\n",
        "\n",
        "    all_results: Dict[str, Any] = {}\n",
        "    for url in test_urls:\n",
        "        print(f\"\\n=== Running on {url} ===\")\n",
        "        company_hint = \"Google\" if \"google\" in url else \"Meta\" if (\"meta\" in url or \"facebook\" in url) else \"Stripe\"\n",
        "        try:\n",
        "            recs = run_on_url(url, company_hint)\n",
        "            print(f\"Extracted {len(recs)} listings\")\n",
        "            for r in recs[:5]:\n",
        "                print(r)\n",
        "            all_results[url] = recs\n",
        "        except Exception as e:\n",
        "            print(\"ERROR:\", e)\n",
        "            all_results[url] = {\"error\": str(e)}\n",
        "\n",
        "    out_path = f\"/content/job_crew/data/outputs.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
        "    print(\"\\nSaved results ->\", out_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGTxfKGJMbCR",
        "outputId": "20981469-f6f1-4918-ad44-0c315b63d2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/job_crew/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python {BASE_DIR}/main.py\n",
        "\n",
        "import os\n",
        "print(\"Data dir contents:\", os.listdir(f\"{BASE_DIR}/data\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HXaBibJM6yC",
        "outputId": "05539ebe-7712-43bd-a530-9645c4897e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Running on https://careers.google.com/jobs/results/ ===\n",
            "Extracted 12 listings\n",
            "{'job_title': 'Careers', 'location': None, 'company': 'Google', 'description_snippet': None, 'apply_link': 'https://www.google.com/about/careers/applications/'}\n",
            "{'job_title': 'work_outlinework_outlineJobsJobs', 'location': None, 'company': 'Google', 'description_snippet': None, 'apply_link': 'https://www.google.com/about/careers/applications/jobs/results/jobs/results'}\n",
            "{'job_title': 'Help', 'location': None, 'company': 'Google', 'description_snippet': None, 'apply_link': 'https://support.google.com/googlecareers'}\n",
            "{'job_title': 'Sign in', 'location': None, 'company': 'Google', 'description_snippet': None, 'apply_link': 'https://accounts.google.com/ServiceLogin?passive=1209600&continue=https%3A%2F%2Fwww.google.com%2Fabout%2Fcareers%2Fapplications%2Fjobs%2Fresults%2F&followup=https%3A%2F%2Fwww.google.com%2Fabout%2Fcareers%2Fapplications%2Fjobs%2Fresults%2F&ec=GAZA6QE'}\n",
            "{'job_title': 'Job search', 'location': None, 'company': 'Google', 'description_snippet': None, 'apply_link': 'https://www.google.com/about/careers/applications/jobs/results/jobs/results'}\n",
            "\n",
            "=== Running on https://www.metacareers.com/jobs/ ===\n",
            "Extracted 33 listings\n",
            "{'job_title': 'Jobs', 'location': None, 'company': 'Meta', 'description_snippet': None, 'apply_link': 'https://www.metacareers.com/jobs'}\n",
            "{'job_title': 'Teams', 'location': None, 'company': 'Meta', 'description_snippet': None, 'apply_link': 'https://www.metacareers.com/jobs'}\n",
            "{'job_title': 'Artificial Intelligence', 'location': None, 'company': 'Meta', 'description_snippet': None, 'apply_link': 'https://www.metacareers.com/teams/technology?tab=AI'}\n",
            "{'job_title': 'Artificial Intelligence', 'location': None, 'company': 'Meta', 'description_snippet': None, 'apply_link': 'https://www.metacareers.com/teams/technology?tab=AI'}\n",
            "{'job_title': 'Artificial Intelligence', 'location': None, 'company': 'Meta', 'description_snippet': None, 'apply_link': 'https://www.metacareers.com/teams/technology?tab=AI'}\n",
            "\n",
            "=== Running on https://stripe.com/jobs/search ===\n",
            "ERROR: Page.goto: Timeout 30000ms exceeded.\n",
            "Call log:\n",
            "  - navigating to \"https://stripe.com/jobs/search\", waiting until \"networkidle\"\n",
            "\n",
            "\n",
            "Saved results -> /content/job_crew/data/outputs.json\n",
            "Data dir contents: ['outputs.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/job_crew/data/outputs.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "M26T-INAPfxL",
        "outputId": "f94dffcb-8223-4543-bb4b-c6f1d59a7723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24c73640-11ba-4691-ba90-1dfaf7c4c43a\", \"outputs.json\", 12349)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}